# üì¶ Cen√°rio 1: Desafio T√©cnico - Microservi√ßo de Rastreamento

## üéØ Objetivo Principal

**Automatizar o processo de rastreio de pedidos** utilizando a API da transportadora "Carriers" e garantir a integra√ß√£o com a arquitetura de microsservi√ßos existente, melhorando a efici√™ncia e reduzindo o trabalho manual.

> **üí° Contexto**: Este √© um desafio t√©cnico onde os outros microservi√ßos (Cota√ß√£o e Contrata√ß√£o) **j√° existem** na empresa. Seu objetivo √© implementar especificamente o **Microservi√ßo de Rastreamento**.

---

## üèóÔ∏è Arquitetura Proposta

### **Componentes do Sistema**

```mermaid
C4Container
    title Arquitetura do Microservi√ßo de Rastreamento
    
    Person(client, "Cliente", "Usu√°rio que quer rastrear pedidos")
    Person(admin, "Admin", "Administrador do sistema")
    
    Container_Boundary(c1, "SmartEnvios - Tracking Microservice") {
        Container(api, "Tracking API", "Node.js + Express", "Endpoints para gerenciar c√≥digos de rastreamento")
        Container(scheduler, "Tracking Scheduler", "Node.js + Cron", "Verifica periodicamente status dos c√≥digos")
        Container(consumer, "Event Consumer", "Node.js + Kafka", "Processa eventos de novos c√≥digos")
    }
    
    ContainerDb(mongo, "MongoDB", "NoSQL Database", "Armazena c√≥digos e eventos de rastreamento")
    Container(kafka, "Apache Kafka", "Message Broker", "Comunica√ß√£o ass√≠ncrona")
    Container(redis, "Redis", "Cache", "Cache de consultas e rate limiting")
    
    System_Ext(carriers, "Carriers API", "API externa da transportadora")
    System_Ext(existing_ms, "Microservi√ßos Existentes", "Cota√ß√£o e Contrata√ß√£o j√° implementados")
    
    Rel(client, api, "Consulta rastreamento", "HTTPS")
    Rel(admin, api, "Gerencia c√≥digos", "HTTPS")
    Rel(api, mongo, "CRUD operations", "MongoDB Driver")
    Rel(api, redis, "Cache queries", "Redis Client")
    Rel(scheduler, carriers, "Consulta status", "HTTPS")
    Rel(scheduler, mongo, "Atualiza eventos", "MongoDB Driver")
    Rel(scheduler, kafka, "Publica eventos", "Kafka Producer")
    Rel(consumer, kafka, "Consome eventos", "Kafka Consumer")
    Rel(existing_ms, kafka, "Envia c√≥digos", "Kafka Producer")
```

### **1. üîß Microservi√ßo de Rastreio de Pedidos**

#### **Responsabilidades:**
- ‚úÖ **Receber c√≥digos** de rastreamento via Kafka ou API
- ‚úÖ **Consultar periodicamente** a API da transportadora 
- ‚úÖ **Detectar mudan√ßas** de status automaticamente
- ‚úÖ **Armazenar eventos** de rastreamento no MongoDB
- ‚úÖ **Publicar atualiza√ß√µes** via Kafka para outros servi√ßos
- ‚úÖ **Otimizar intervalos** de verifica√ß√£o baseado no status

#### **Comunica√ß√£o:**
- **üîÑ Ass√≠ncrona (Kafka)**: Para receber novos c√≥digos e publicar atualiza√ß√µes
- **üåê S√≠ncrona (HTTP)**: Para consultar API Carriers e servir dados aos clientes

### **2. üóÑÔ∏è Banco de Dados MongoDB**

#### **Justificativa:**
- **Flexibilidade**: Estrutura ideal para eventos de rastreamento
- **Performance**: Consultas r√°pidas por trackingCode (chave √∫nica)
- **Escalabilidade**: Gerencia grandes volumes de dados n√£o estruturados

#### **Estrutura de Dados:**
```json
{
  "_id": "ObjectId",
  "trackingCode": "SM82886187440BM",
  "carrier": "Carriers", 
  "contractId": "12345", // Refer√™ncia ao contrato existente
  "customerId": "customer_123",
  "status": "in_transit",
  "isActive": true,
  "createdAt": "2025-01-20T10:00:00Z",
  "lastCheckedAt": "2025-01-22T15:30:00Z",
  "nextCheckAt": "2025-01-22T16:00:00Z",
  "events": [
    {
      "id": "evt_001",
      "timestamp": "2025-01-20T10:30:00Z",
      "status": "posted",
      "location": "S√£o Paulo, SP",
      "description": "Objeto postado",
      "isDelivered": false
    },
    {
      "id": "evt_002", 
      "timestamp": "2025-01-21T14:00:00Z",
      "status": "in_transit",
      "location": "Rio de Janeiro, RJ", 
      "description": "Objeto em tr√¢nsito",
      "isDelivered": false
    },
    {
      "id": "evt_003",
      "timestamp": "2025-01-22T09:15:00Z", 
      "status": "delivered",
      "location": "Rio de Janeiro, RJ",
      "description": "Objeto entregue ao destinat√°rio",
      "isDelivered": true
    }
  ],
  "metadata": {
    "checkInterval": 30, // minutos
    "errorCount": 0,
    "lastError": null,
    "totalChecks": 47
  }
}
```

### **3. ‚è∞ Scheduler Inteligente**

#### **Implementa√ß√£o:**
- **Local**: **Node.js + node-cron** para simplicidade
- **Produ√ß√£o**: **Quartz Scheduler** ou **AWS EventBridge**

#### **Estrat√©gia de Verifica√ß√£o:**
```typescript
interface CheckStrategy {
  posted: number;        // 5 min - acabou de ser postado
  in_transit: number;    // 30 min - viajando normalmente  
  out_for_delivery: number; // 10 min - saindo para entrega
  delivered: number;     // 0 - para de verificar
  exception: number;     // 15 min - problema detectado
  unknown: number;       // 60 min - status desconhecido
}
```

### **4. üì° Produtor de Eventos (Kafka)**

#### **T√≥picos:**
- **`tracking.status.updated`** - Mudan√ßas de status
- **`tracking.code.delivered`** - Entregas finalizadas  
- **`tracking.error.detected`** - Problemas identificados

#### **Exemplo de Evento:**
```json
{
  "eventType": "tracking.status.updated",
  "trackingCode": "SM82886187440BM",
  "previousStatus": "in_transit", 
  "currentStatus": "out_for_delivery",
  "timestamp": "2025-01-22T08:30:00Z",
  "location": "Rio de Janeiro, RJ",
  "customerId": "customer_123",
  "contractId": "12345"
}
```

### **5. üéØ Consumidor de Eventos (Kafka)**

#### **T√≥picos Consumidos:**
- **`contract.created`** - Novos contratos com c√≥digos para rastrear
- **`quote.converted`** - Cota√ß√µes que viraram contratos

---

## üèóÔ∏è Padr√µes Arquiteturais

### **Princ√≠pios Fundamentais**
- **Domain Driven Design (DDD)**: Organiza√ß√£o por dom√≠nio de rastreamento
- **Event-Driven Architecture**: Comunica√ß√£o ass√≠ncrona via Kafka
- **API Gateway Pattern**: Ponto centralizado de acesso (simulado)
- **Circuit Breaker Pattern**: Resili√™ncia na comunica√ß√£o com Carriers API
- **Repository Pattern**: Abstra√ß√£o de persist√™ncia MongoDB
- **Command Query Responsibility Segregation (CQRS)**: Separa√ß√£o de opera√ß√µes
- **Saga Pattern**: Coordena√ß√£o de transa√ß√µes distribu√≠das
- **Retry Pattern**: Recupera√ß√£o autom√°tica de falhas tempor√°rias

### **Benef√≠cios da Aplica√ß√£o dos Padr√µes**
1. **Isolamento de Falhas**: Circuit breaker evita cascata de erros
2. **Escalabilidade**: Event-driven permite processamento ass√≠ncrono
3. **Manutenibilidade**: DDD facilita evolu√ß√£o do dom√≠nio
4. **Testabilidade**: Repository pattern permite mock de dados
5. **Resili√™ncia**: Retry pattern recupera falhas tempor√°rias
6. **Performance**: CQRS otimiza opera√ß√µes de leitura/escrita

---

## üîÑ Fluxo da Solu√ß√£o

### **1. üì• Recebimento de C√≥digo**
```mermaid
sequenceDiagram
    participant MS as Microservi√ßos Existentes
    participant K as Kafka
    participant T as Tracking Service
    participant DB as MongoDB
    
    MS->>K: Publica "contract.created"
    K->>T: Consome evento
    T->>T: Extrai trackingCode
    T->>DB: Salva c√≥digo para monitorar
    T->>T: Agenda primeira verifica√ß√£o
```

### **2. üîç Consulta Inicial**
```bash
curl --request GET \
  --url "http://api.carriers.com.br/client/Carriers/Tracking/SM82886187440BM" \
  --header "Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9..."
```

**Resposta Esperada:**
```json
{
  "success": true,
  "trackingCode": "SM82886187440BM",
  "events": [
    {
      "date": "2025-01-20 10:30:00",
      "status": "Objeto postado",
      "location": "S√£o Paulo, SP"
    },
    {
      "date": "2025-01-21 14:00:00", 
      "status": "Objeto em tr√¢nsito",
      "location": "Rio de Janeiro, RJ"
    }
  ]
}
```

### **3. üíæ Armazenamento e Processamento**
```mermaid
sequenceDiagram
    participant S as Scheduler
    participant C as Carriers API
    participant T as Tracking Service
    participant DB as MongoDB
    participant K as Kafka
    
    loop A cada intervalo configurado
        S->>T: Verifica c√≥digos pendentes
        T->>DB: Busca c√≥digos ativos
        T->>C: Consulta status na Carriers
        C->>T: Retorna eventos atualizados
        T->>T: Compara com eventos existentes
        alt Novos eventos detectados
            T->>DB: Salva novos eventos
            T->>K: Publica atualiza√ß√£o
        end
        T->>T: Calcula pr√≥ximo intervalo
        T->>DB: Atualiza nextCheckAt
    end
```

### **4. üì¢ Notifica√ß√£o e Integra√ß√£o**
```mermaid
flowchart LR
    A[Tracking atualizado] --> B[Kafka Event]
    B --> C[Notification Service]
    B --> D[Dashboard Service] 
    B --> E[Contract Service]
    B --> F[Analytics Service]
    
    C --> G[üìß Email Cliente]
    C --> H[üì± SMS/WhatsApp]
    D --> I[üìä Dashboard Tempo Real]
    E --> J[üìã Atualiza Status Contrato]
    F --> K[üìà M√©tricas de Entrega]
```

---

## üèõÔ∏è Arquitetura C4 - Diagramas do Sistema

### **C1 - Diagrama de Contexto**
*Vis√£o geral do microservi√ßo de rastreamento e suas intera√ß√µes externas*

```mermaid
C4Context
    title Contexto do Microservi√ßo de Rastreamento
    
    Person(cliente, "Cliente", "Consulta status dos rastreamentos")
    Person(admin, "Administrador", "Monitora e gerencia rastreamentos")
    
    System(tracking, "Tracking Microservice", "Automatiza rastreamento de pedidos via API Carriers")
    
    System_Ext(carriers, "API Carriers", "Servi√ßo externo da transportadora")
    System_Ext(existing_ms, "Microservi√ßos Existentes", "Cota√ß√£o e Contrata√ß√£o (j√° implementados)")
    System_Ext(notification, "Notification Service", "Envia alertas e notifica√ß√µes")
    System_Ext(analytics, "Analytics Service", "Coleta m√©tricas de entrega")
    
    Rel(cliente, tracking, "Consulta rastreamentos", "HTTPS/REST")
    Rel(admin, tracking, "Monitora sistema", "HTTPS/Dashboard")
    Rel(tracking, carriers, "Busca atualiza√ß√µes", "HTTPS/REST")
    Rel(existing_ms, tracking, "Envia c√≥digos", "Kafka Events")
    Rel(tracking, notification, "Publica mudan√ßas", "Kafka Events")
    Rel(tracking, analytics, "Envia m√©tricas", "Kafka Events")
```

### **C2 - Diagrama de Cont√™ineres**
*Aplica√ß√µes e dados que comp√µem o microservi√ßo de rastreamento*

```mermaid
C4Container
    title Cont√™ineres do Microservi√ßo de Rastreamento
    
    Person(cliente, "Cliente")
    Person(admin, "Admin")
    
    Container_Boundary(c1, "Tracking Microservice") {
        Container(api, "Tracking API", "Node.js + Express", "REST API para opera√ß√µes de rastreamento")
        Container(scheduler, "Tracking Scheduler", "Node.js + Cron", "Jobs autom√°ticos de verifica√ß√£o")
        Container(consumer, "Event Consumer", "Node.js + Kafka", "Processa eventos de novos c√≥digos")
        Container(worker, "Background Workers", "Node.js + Bull", "Processamento em background")
    }
    
    ContainerDb(mongodb, "MongoDB", "NoSQL Database", "Armazena c√≥digos e eventos")
    Container(redis, "Redis", "Cache + Queue", "Cache de consultas e filas de jobs")
    Container(kafka, "Apache Kafka", "Message Broker", "Eventos ass√≠ncronos")
    
    System_Ext(carriers, "Carriers API")
    System_Ext(existing, "Existing Services")
    
    Rel(cliente, api, "HTTP/REST")
    Rel(admin, api, "HTTP/REST")
    Rel(api, mongodb, "Read/Write")
    Rel(api, redis, "Cache ops")
    Rel(scheduler, mongodb, "Read tracking codes")
    Rel(scheduler, carriers, "HTTP/REST")
    Rel(scheduler, kafka, "Publish events")
    Rel(consumer, kafka, "Consume events")
    Rel(consumer, mongodb, "Store new codes")
    Rel(worker, redis, "Process jobs")
    Rel(existing, kafka, "Send events")
```

### **C3 - Diagrama de Componentes**
*Componentes internos do microservi√ßo de rastreamento*

```mermaid
C4Component
    title Componentes do Tracking Microservice
    
    Container_Boundary(api, "Tracking API") {
        Component(controller, "Tracking Controller", "Express Router", "Endpoints REST para rastreamento")
        Component(middleware, "Auth Middleware", "Express Middleware", "Autentica√ß√£o e valida√ß√£o")
        Component(validator, "Input Validator", "Zod Schemas", "Valida√ß√£o de entrada")
    }
    
    Container_Boundary(app, "Application Layer") {
        Component(addUseCase, "Add Tracking Use Case", "Command Handler", "Adiciona novos c√≥digos")
        Component(updateUseCase, "Update Tracking Use Case", "Command Handler", "Atualiza status dos c√≥digos")
        Component(queryUseCase, "Query Tracking Use Case", "Query Handler", "Consulta dados de rastreamento")
        Component(scheduler, "Tracking Scheduler", "Cron Jobs", "Agenda verifica√ß√µes autom√°ticas")
    }
    
    Container_Boundary(domain, "Domain Layer") {
        Component(trackingCode, "TrackingCode", "Aggregate", "Entidade principal do rastreamento")
        Component(trackingEvent, "TrackingEvent", "Entity", "Eventos de rastreamento")
        Component(domainService, "Tracking Service", "Domain Service", "Regras de neg√≥cio complexas")
        Component(repository, "Repository Interface", "Interface", "Abstra√ß√£o de persist√™ncia")
    }
    
    Container_Boundary(infra, "Infrastructure Layer") {
        Component(mongoRepo, "Mongo Repository", "MongoDB Driver", "Implementa√ß√£o de persist√™ncia")
        Component(carriersClient, "Carriers Client", "HTTP Client", "Integra√ß√£o com API Carriers")
        Component(kafkaProducer, "Kafka Producer", "Kafka Client", "Publica√ß√£o de eventos")
        Component(redisCache, "Redis Cache", "Redis Client", "Cache e rate limiting")
    }
    
    Rel(controller, addUseCase, "calls")
    Rel(controller, updateUseCase, "calls") 
    Rel(controller, queryUseCase, "calls")
    Rel(addUseCase, trackingCode, "creates")
    Rel(updateUseCase, domainService, "uses")
    Rel(queryUseCase, repository, "queries")
    Rel(scheduler, updateUseCase, "triggers")
    Rel(domainService, repository, "uses")
    Rel(repository, mongoRepo, "implemented by")
    Rel(updateUseCase, carriersClient, "calls")
    Rel(updateUseCase, kafkaProducer, "publishes")
    Rel(carriersClient, redisCache, "caches")
```

### **C4 - Diagrama de C√≥digo - Use Case de Rastreamento**
*Estrutura de classes do caso de uso principal*

```mermaid
classDiagram
    class TrackingController {
        +addTrackingCode(request: AddTrackingRequest): Promise~TrackingResponse~
        +getTracking(code: string): Promise~TrackingResponse~
        +refreshTracking(code: string): Promise~TrackingResponse~
        +listTracking(query: ListTrackingQuery): Promise~TrackingListResponse~
        -validateRequest(request: any): ValidationResult
        -handleError(error: Error): ErrorResponse
    }
    
    class UpdateTrackingUseCase {
        -trackingRepository: TrackingRepository
        -carriersClient: CarriersTrackingClient
        -eventPublisher: EventPublisher
        -cacheService: TrackingCacheService
        +execute(trackingCode: string): Promise~TrackingEvent[]~
        -processNewEvents(tracking: TrackingCode, events: TrackingEvent[]): Promise~TrackingEvent[]~
        -updateTrackingStatus(tracking: TrackingCode, events: TrackingEvent[]): Promise~void~
        -calculateNextCheck(tracking: TrackingCode, error?: Error): Date
    }
    
    class TrackingCode {
        +id: string
        +code: string
        +carrier: string
        +status: TrackingStatus
        +lastCheckedAt: Date
        +nextCheckAt: Date
        +isActive: boolean
        +create(data: CreateTrackingData): TrackingCode
        +markAsDelivered(): void
        +updateNextCheck(interval: number): void
        +isExpired(): boolean
    }
    
    class TrackingEvent {
        +id: string
        +trackingCodeId: string
        +timestamp: Date
        +status: string
        +location: string
        +description: string
        +isDelivered: boolean
        +isException: boolean
        +create(data: EventData): TrackingEvent
    }
    
    class CarriersTrackingClient {
        -baseUrl: string
        -token: string
        -httpClient: AxiosInstance
        +trackShipment(trackingCode: string): Promise~CarriersTrackingResponse~
        +healthCheck(): Promise~HealthStatus~
        -buildRequest(code: string): AxiosRequestConfig
        -handleApiError(error: AxiosError): CarriersApiError
    }
    
    class TrackingRepository {
        <<interface>>
        +findByCode(code: string): Promise~TrackingCode | null~
        +save(tracking: TrackingCode): Promise~TrackingCode~
        +findPendingCodes(): Promise~TrackingCode[]~
        +findByCustomer(customerId: string): Promise~TrackingCode[]~
    }
    
    class MongoTrackingRepository {
        -model: TrackingCodeModel
        +findByCode(code: string): Promise~TrackingCode | null~
        +save(tracking: TrackingCode): Promise~TrackingCode~
        +findPendingCodes(): Promise~TrackingCode[]~
        +findByCustomer(customerId: string): Promise~TrackingCode[]~
        -mapToDomain(doc: Document): TrackingCode
        -mapToDocument(entity: TrackingCode): Document
    }
    
    class KafkaEventPublisher {
        -producer: Producer
        -logger: Logger
        +publish(eventType: string, data: any): Promise~void~
        -getTopicForEvent(eventType: string): string
        -createEvent(type: string, data: any): DomainEvent
    }
    
    class TrackingScheduler {
        -trackingService: TrackingService
        -isRunning: boolean
        +start(): void
        +stop(): void
        -processPendingTrackingCodes(): Promise~void~
        -processTrackingCode(code: TrackingCode): Promise~void~
        -cleanupOldEvents(): Promise~void~
    }

    TrackingController --> UpdateTrackingUseCase
    UpdateTrackingUseCase --> TrackingRepository
    UpdateTrackingUseCase --> CarriersTrackingClient
    UpdateTrackingUseCase --> KafkaEventPublisher
    UpdateTrackingUseCase --> TrackingCode
    UpdateTrackingUseCase --> TrackingEvent
    TrackingRepository <|-- MongoTrackingRepository
    TrackingScheduler --> UpdateTrackingUseCase
    MongoTrackingRepository --> TrackingCode
    KafkaEventPublisher --> TrackingEvent
```

### **üîÑ Fluxo de Dados - Event-Driven Architecture**
*Como os eventos fluem pelo sistema de rastreamento*

```mermaid
sequenceDiagram
    participant MS as Microservi√ßos Existentes
    participant K as Kafka
    participant TC as Tracking Consumer
    participant TS as Tracking Scheduler
    participant CA as Carriers API
    participant DB as MongoDB
    participant KP as Kafka Producer
    participant NS as Notification Service
    
    Note over MS, NS: 1. Adi√ß√£o de Novo C√≥digo
    MS->>K: Publica "contract.created"
    K->>TC: Consome evento
    TC->>DB: Salva c√≥digo para monitorar
    TC->>DB: Agenda primeira verifica√ß√£o
    
    Note over MS, NS: 2. Verifica√ß√£o Autom√°tica
    loop A cada intervalo
        TS->>DB: Busca c√≥digos pendentes
        TS->>CA: Consulta status atual
        CA-->>TS: Retorna eventos
        TS->>DB: Compara e salva novos eventos
        
        alt Novos eventos detectados
            TS->>KP: Publica "tracking.status.updated"
            KP->>K: Envia evento
            K->>NS: Notifica interessados
        end
        
        TS->>DB: Atualiza nextCheckAt
    end
    
    Note over MS, NS: 3. Consulta Manual
    MS->>TS: GET /api/v1/tracking/{code}
    TS->>DB: Busca eventos atuais
    DB-->>TS: Retorna dados
    TS-->>MS: Resposta com eventos
    
    Note over MS, NS: 4. Finaliza√ß√£o
    TS->>DB: Detecta entrega
    TS->>KP: Publica "tracking.delivered"
    TS->>DB: Marca como inativo
```

---

## üéØ Endpoints da API

### **üì• Adicionar C√≥digo de Rastreamento**
```http
POST /api/v1/tracking
Content-Type: application/json

{
  "trackingCode": "SM82886187440BM",
  "carrier": "Carriers",
  "contractId": "12345",
  "customerId": "customer_123"
}
```

### **üîç Consultar Rastreamento** 
```http
GET /api/v1/tracking/SM82886187440BM
```

### **üîÑ For√ßar Atualiza√ß√£o**
```http
POST /api/v1/tracking/SM82886187440BM/refresh
```

### **üìã Listar Rastreamentos**
```http
GET /api/v1/tracking?customerId=customer_123&status=in_transit
```

### **‚öôÔ∏è Health Check**
```http
GET /api/v1/health
```

---

## üîß Tecnologias Utilizadas

### **Core Stack:**
- **Runtime**: Node.js 20+ LTS
- **Language**: TypeScript 5+
- **Framework**: Express.js 4+
- **Database**: MongoDB 7+
- **Cache**: Redis 7+
- **Message Broker**: Apache Kafka 3+

### **Bibliotecas Principais:**
- **HTTP Client**: Axios para Carriers API
- **Validation**: Zod para schemas
- **Logging**: Winston estruturado  
- **Scheduler**: node-cron
- **Testing**: Jest + Supertest
- **Monitoring**: Prometheus client

### **DevOps:**
- **Container**: Docker + Docker Compose
- **Process Management**: PM2
- **Environment**: dotenv
- **Linting**: ESLint + Prettier

---

## üìä Argumenta√ß√£o das Escolhas

### **1. üóÑÔ∏è MongoDB (NoSQL)**
#### **‚úÖ Vantagens:**
- **Flexibilidade**: Eventos podem ter estruturas diferentes
- **Performance**: √çndices otimizados para trackingCode
- **Escalabilidade**: Sharding horizontal natural
- **Agrega√ß√µes**: Pipeline poderoso para relat√≥rios

#### **üìä Alternativas Consideradas:**
- **PostgreSQL**: Mais complexo para eventos semi-estruturados
- **Elasticsearch**: Overkill para esta funcionalidade espec√≠fica

### **2. üì° Apache Kafka**
#### **‚úÖ Vantagens:**
- **Integra√ß√£o**: J√° usado pelos microservi√ßos existentes
- **Durabilidade**: Eventos n√£o se perdem
- **Escalabilidade**: Milh√µes de eventos por segundo
- **Ordem garantida**: Por parti√ß√£o

#### **üìä Alternativas Consideradas:**
- **RabbitMQ**: Menos perform√°tico para alto volume
- **Redis Pub/Sub**: Sem persist√™ncia

### **3. ‚ö° Redis Cache**
#### **‚úÖ Vantagens:**
- **Rate Limiting**: Evita sobrecarga da Carriers API
- **Cache de Consultas**: Responses frequentes
- **Session Storage**: Para dashboards
- **Distributed Locks**: Para scheduler

### **4. üèóÔ∏è Arquitetura de Microservi√ßos**
#### **‚úÖ Vantagens:**
- **Separa√ß√£o de Responsabilidades**: Cada servi√ßo tem fun√ß√£o clara
- **Escalabilidade**: Escalar apenas rastreamento se necess√°rio  
- **Manutenibilidade**: Times independentes
- **Tecnologia**: Stacks otimizadas por dom√≠nio

---

## ‚è±Ô∏è Cronograma de Desenvolvimento

### **üéØ Detalhamento por Dia:**

#### **Dia 1: Setup e Infraestrutura** 
- [x] Cria√ß√£o do reposit√≥rio estruturado
- [x] Docker Compose completo (MongoDB, Kafka, Redis)
- [x] Estrutura de pastas e arquivos base
- [x] Configura√ß√£o de ambiente (.env)

#### **Dia 2: API Base**
- [ ] Express.js configurado com TypeScript
- [ ] Endpoints CRUD para c√≥digos de rastreamento
- [ ] Valida√ß√µes com Zod
- [ ] Conex√£o MongoDB com Mongoose

#### **Dia 3: Integra√ß√£o Carriers**
- [ ] Cliente HTTP para Carriers API
- [ ] Mapeamento de responses
- [ ] Error handling e retry logic
- [ ] Cache Redis para rate limiting

#### **Dia 4: Scheduler e Jobs**
- [ ] Sistema de jobs com node-cron
- [ ] L√≥gica de intervalos inteligentes
- [ ] Kafka producer para eventos
- [ ] Consumer para novos c√≥digos

#### **Dia 5: Testes e Monitoramento**
- [ ] Testes unit√°rios (>80% coverage)
- [ ] Testes de integra√ß√£o com Carriers
- [ ] Health checks e m√©tricas
- [ ] Logging estruturado

#### **Dia 6: Deploy e Documenta√ß√£o**
- [ ] Docker otimizado para produ√ß√£o
- [ ] OpenAPI/Swagger documentation
- [ ] README t√©cnico completo
- [ ] V√≠deo de demonstra√ß√£o

---

## üß™ Crit√©rios de Aceita√ß√£o

### **‚úÖ Funcionalidades Obrigat√≥rias:**
1. **API REST** funcional com todos os endpoints
2. **Integra√ß√£o Carriers** com error handling robusto
3. **Scheduler** verificando c√≥digos automaticamente
4. **Kafka** produzindo e consumindo eventos
5. **MongoDB** persistindo dados corretamente
6. **Health checks** reportando status do sistema

### **üéØ Crit√©rios de Qualidade:**
- **Cobertura de testes** ‚â• 80%
- **Response time API** ‚â§ 200ms (P95)
- **Error rate** ‚â§ 1%
- **Uptime** ‚â• 99.9%
- **Documenta√ß√£o** completa e atualizada

### **üìä M√©tricas de Performance:**
- **C√≥digos processados**: 1000+ por hora
- **Lat√™ncia Carriers API**: ‚â§ 2 segundos
- **Memory usage**: ‚â§ 512MB
- **CPU usage**: ‚â§ 50% (load normal)

---

## üöÄ Pr√≥ximos Passos

### **1. üìã Planejamento (Hoje)**
- [x] Estrutura√ß√£o do reposit√≥rio ‚úÖ
- [x] Documenta√ß√£o da arquitetura ‚úÖ 
- [ ] Refinamento dos requisitos

### **2. üîß Desenvolvimento (2-5 dias)**
- [ ] Implementa√ß√£o seguindo o cronograma
- [ ] Code reviews cont√≠nuos
- [ ] Testes em paralelo

### **3. üé¨ Entrega (Dia 6)**
- [ ] Demonstra√ß√£o funcional
- [ ] V√≠deo explicativo
- [ ] Documenta√ß√£o final

---

## üìö Recursos e Refer√™ncias

### **üîó Links √öteis:**
- **Carriers API**: [Documenta√ß√£o oficial](http://api.carriers.com.br)
- **MongoDB**: [Best practices](https://docs.mongodb.com/manual/best-practices/)
- **Apache Kafka**: [Node.js client](https://kafka.js.org/)
- **Express.js**: [TypeScript setup](https://expressjs.com/en/advanced/typescript.html)

### **üìñ Documenta√ß√£o T√©cnica:**
- **API Specification**: `docs/api/openapi.yaml` (a ser criado)
- **Database Schema**: `docs/database/mongodb-schema.md` (a ser criado)
- **Event Schemas**: `docs/events/kafka-events.md` (a ser criado)

---

## üéì Entendendo a Arquitetura C4 - Guia Passo a Passo

### **üìö O Que √© o Modelo C4?**

O modelo C4 √© como um **mapa com diferentes n√≠veis de zoom** da sua arquitetura de software. Imagine que voc√™ est√° explicando o sistema de rastreamento para pessoas diferentes:

- **üåç C1 (Contexto)**: Vista de sat√©lite - "O que o sistema faz no mundo?"
- **üèôÔ∏è C2 (Cont√™ineres)**: Vista da cidade - "Quais aplica√ß√µes comp√µem o sistema?"
- **üè≠ C3 (Componentes)**: Vista dos bairros - "Como cada aplica√ß√£o √© organizada internamente?"
- **üîß C4 (C√≥digo)**: Vista das ruas - "Como o c√≥digo est√° estruturado?"

### **üîç Detalhamento de Cada N√≠vel**

#### **üìä C1 - Contexto: "A Vista Geral"**

**Para quem √©**: Stakeholders, gerentes, product owners  
**Pergunta que responde**: "Como o microservi√ßo de rastreamento se encaixa no ecossistema?"

**O que voc√™ v√™**:
- ‚úÖ O microservi√ßo como uma "caixa preta"
- ‚úÖ Outros sistemas que interagem com ele
- ‚úÖ Usu√°rios que o utilizam
- ‚úÖ APIs externas que consome

**Como funciona no nosso caso**:
```mermaid
graph TB
    Cliente[üë§ Cliente] --> Tracking[üì¶ Tracking Microservice]
    ExistingMS[üè¢ Microservi√ßos Existentes] --> Tracking
    Tracking --> Carriers[üöõ API Carriers]
    Tracking --> Notification[üìß Notification Service]
```

**Por que √© importante**: Todos entendem o "quadro geral" sem se perder em detalhes t√©cnicos.

---

#### **üèóÔ∏è C2 - Cont√™ineres: "Os Bairros da Cidade"**

**Para quem √©**: Arquitetos de software, tech leads  
**Pergunta que responde**: "Quais aplica√ß√µes e bancos de dados comp√µem o microservi√ßo?"

**O que voc√™ v√™**:
- ‚úÖ API REST (Node.js + Express)
- ‚úÖ Scheduler autom√°tico (Node.js + Cron)
- ‚úÖ Event Consumer (Kafka)
- ‚úÖ MongoDB (banco de dados)
- ‚úÖ Redis (cache)

**Como funciona no nosso caso**:
```mermaid
graph TB
    subgraph "Tracking Microservice"
        API[üåê REST API]
        Scheduler[‚è∞ Scheduler]
        Consumer[üì• Event Consumer]
    end
    
    MongoDB[(üóÑÔ∏è MongoDB)]
    Redis[(‚ö° Redis)]
    Kafka[üì° Kafka]
    
    API --> MongoDB
    Scheduler --> MongoDB
    Consumer --> MongoDB
    API --> Redis
```

**Por que √© importante**: Define os componentes que precisam ser deployados e como se comunicam.

---

#### **‚öôÔ∏è C3 - Componentes: "Dentro de Cada F√°brica"**

**Para quem √©**: Desenvolvedores experientes, l√≠deres t√©cnicos  
**Pergunta que responde**: "Como a API REST est√° organizada internamente?"

**O que voc√™ v√™**:
- ‚úÖ Controllers (recebem requests)
- ‚úÖ Use Cases (l√≥gica de neg√≥cio)
- ‚úÖ Repositories (acesso a dados)
- ‚úÖ Services (integra√ß√µes externas)

**Como funciona no nosso caso**:
```mermaid
graph TB
    Controller[üéØ Tracking Controller] --> UseCase[‚ö° Update Tracking Use Case]
    UseCase --> Repository[üóÑÔ∏è Tracking Repository]
    UseCase --> Client[üåê Carriers Client]
    UseCase --> Publisher[üì° Event Publisher]
```

**Por que √© importante**: Desenvolvedores sabem onde implementar cada funcionalidade.

---

#### **üíª C4 - C√≥digo: "A Planta Baixa"**

**Para quem √©**: Desenvolvedores implementando  
**Pergunta que responde**: "Quais classes e m√©todos preciso criar?"

**O que voc√™ v√™**:
- ‚úÖ Classes espec√≠ficas (`TrackingController`, `UpdateTrackingUseCase`)
- ‚úÖ M√©todos p√∫blicos e privados
- ‚úÖ Interfaces e implementa√ß√µes
- ‚úÖ Relacionamentos entre classes

**Como funciona no nosso caso**:
```typescript
class TrackingController {
  +getTracking(code: string): Promise<TrackingResponse>
  +refreshTracking(code: string): Promise<TrackingResponse>
  
  constructor(
    private updateUseCase: UpdateTrackingUseCase
  ) {}
}
```

**Por que √© importante**: Guia exato para implementa√ß√£o do c√≥digo.

### **üîÑ Fluxo de Trabalho Natural**

1. **üíº Reuni√£o de Neg√≥cio**: Use C1 para alinhar expectativas
2. **üèóÔ∏è Design de Arquitetura**: Use C2 para definir deploy
3. **üë®‚Äçüíª Design de C√≥digo**: Use C3 para organizar desenvolvimento
4. **‚å®Ô∏è Implementa√ß√£o**: Use C4 para escrever c√≥digo

### **üí° Dicas Importantes**

#### **‚úÖ Fa√ßa**:
- Mantenha **consist√™ncia** entre os n√≠veis
- Use **linguagem simples** em cada n√≠vel
- **Atualize** diagramas quando o c√≥digo mudar

#### **‚ùå N√£o Fa√ßa**:
- Misturar n√≠veis diferentes no mesmo diagrama
- Mostrar detalhes de c√≥digo no C1
- Criar diagramas que ningu√©m entende

### **üéØ Exemplo Pr√°tico de Uso**

**Situa√ß√£o**: Novo desenvolvedor entra na equipe

1. **Dia 1**: Mostrar C1 - "Entenda o que fazemos"
2. **Dia 2**: Mostrar C2 - "Veja como deployamos"  
3. **Semana 1**: Mostrar C3 - "Entenda a organiza√ß√£o interna"
4. **Semana 2**: Mostrar C4 - "Aqui est√° o c√≥digo que voc√™ vai mexer"

### **üìà Benef√≠cios Concretos**

- **‚ö° Onboarding mais r√°pido**: Novos devs entendem progressivamente
- **üó£Ô∏è Comunica√ß√£o melhor**: Cada stakeholder v√™ o que precisa
- **üîß Manuten√ß√£o facilitada**: Mudan√ßas s√£o documentadas visualmente
- **üìã Documenta√ß√£o viva**: Diagramas evoluem com o c√≥digo

---

## ‚ö° Fluxo de Execu√ß√£o Detalhado

### **üîÑ 1. Ciclo de Vida Completo de um C√≥digo de Rastreamento**

#### **Fase 1: Recebimento (2-5 segundos)**
```mermaid
sequenceDiagram
    participant MS as Microservi√ßo Existente
    participant K as Kafka
    participant TC as Tracking Consumer
    participant DB as MongoDB
    participant Cache as Redis
    
    MS->>K: Publica evento "contract.created"
    Note over K: Evento cont√©m trackingCode: "SM123BR"
    K->>TC: Consumer recebe evento
    TC->>TC: Valida estrutura do evento
    TC->>Cache: Verifica duplicatas (5min TTL)
    
    alt C√≥digo n√£o duplicado
        TC->>DB: Salva novo TrackingCode
        Note over DB: Status: "pending", nextCheckAt: agora + 5min
        TC->>Cache: Marca como processado
    else C√≥digo duplicado
        TC->>TC: Log warning e ignora
    end
```

#### **Fase 2: Primeira Verifica√ß√£o (30-60 segundos)**
```mermaid
sequenceDiagram
    participant S as Scheduler
    participant DB as MongoDB
    participant CA as Carriers API
    participant Cache as Redis
    participant KP as Kafka Producer
    
    Note over S: Job roda a cada 1 minuto
    S->>DB: SELECT * FROM tracking WHERE nextCheckAt <= NOW()
    DB-->>S: Retorna c√≥digos pendentes
    
    loop Para cada c√≥digo
        S->>Cache: Verifica rate limit (100 req/min)
        
        alt Rate limit OK
            S->>CA: GET /Tracking/{code}
            CA-->>S: Retorna eventos da transportadora
            S->>S: Mapeia eventos para formato interno
            S->>DB: Compara com eventos existentes
            
            alt Novos eventos encontrados
                S->>DB: INSERT novos eventos
                S->>KP: Publica "tracking.status.updated"
                S->>DB: UPDATE nextCheckAt = agora + intervalo
            else Sem novos eventos
                S->>DB: UPDATE lastCheckedAt = agora
                S->>DB: UPDATE nextCheckAt = agora + intervalo
            end
        else Rate limit atingido
            S->>S: Agenda para pr√≥xima execu√ß√£o
        end
    end
```

#### **Fase 3: Monitoramento Cont√≠nuo (Horas/Dias)**
```mermaid
sequenceDiagram
    participant S as Scheduler
    participant DB as MongoDB
    participant CA as Carriers API
    participant KP as Kafka Producer
    participant IS as Interval Strategy
    
    Note over S: Loop cont√≠nuo baseado em status
    
    loop At√© entrega ou expira√ß√£o
        S->>DB: Busca c√≥digos ativos
        S->>IS: Calcula intervalo baseado no status
        Note over IS: posted: 5min, in_transit: 30min, out_for_delivery: 10min
        
        S->>CA: Verifica status atual
        
        alt Status mudou
            S->>DB: Atualiza status do c√≥digo
            S->>KP: Publica mudan√ßa de status
            
            alt Status = "delivered"
                S->>DB: isActive = false
                S->>KP: Publica "tracking.delivered"
                Note over S: Para monitoramento
            else Status = "exception"
                S->>IS: Intervalo = 15 min (mais frequente)
                S->>KP: Publica "tracking.exception"
            end
        end
        
        S->>S: Sleep at√© pr√≥ximo intervalo
    end
```

#### **Fase 4: Consultas da API (Tempo Real)**
```mermaid
sequenceDiagram
    participant C as Cliente
    participant API as Tracking API
    participant Cache as Redis
    participant DB as MongoDB
    participant Validator as Input Validator
    
    C->>API: GET /api/v1/tracking/SM123BR
    API->>Validator: Valida formato do c√≥digo
    
    alt C√≥digo v√°lido
        API->>Cache: Busca resultado cacheado
        
        alt Cache hit
            Cache-->>API: Retorna dados cacheados
            API-->>C: Response com eventos
        else Cache miss
            API->>DB: Busca tracking + eventos
            DB-->>API: Retorna dados completos
            API->>Cache: Armazena no cache (5min TTL)
            API-->>C: Response com eventos
        end
    else C√≥digo inv√°lido
        API-->>C: 400 Bad Request
    end
```

### **üéØ 2. Fluxos de Erro e Recupera√ß√£o**

#### **Recupera√ß√£o de Falhas da API Carriers**
```mermaid
sequenceDiagram
    participant S as Scheduler
    participant CA as Carriers API
    participant DB as MongoDB
    participant ES as Error Strategy
    
    S->>CA: Verifica tracking code
    CA-->>S: 429 Rate Limit / 500 Server Error
    
    S->>ES: Calcula backoff exponencial
    Note over ES: Retry 1: 1s, Retry 2: 2s, Retry 3: 4s
    
    loop Max 3 tentativas
        S->>S: Wait backoff time
        S->>CA: Retry request
        
        alt Sucesso
            CA-->>S: Dados v√°lidos
            S->>DB: Reset error count
        else Falha continua
            S->>ES: Incrementa error count
            S->>DB: UPDATE nextCheckAt = agora + (interval * 2^errorCount)
            Note over DB: M√°ximo 24h entre tentativas
        end
    end
```

#### **Tratamento de Dados Inconsistentes**
```mermaid
sequenceDiagram
    participant S as Scheduler
    participant CA as Carriers API
    participant DV as Data Validator
    participant DB as MongoDB
    participant KP as Kafka Producer
    
    S->>CA: Busca eventos
    CA-->>S: Retorna dados da API
    S->>DV: Valida estrutura dos eventos
    
    alt Dados v√°lidos
        DV-->>S: Eventos validados
        S->>DB: Processa normalmente
    else Dados inv√°lidos/corrompidos
        DV-->>S: Erro de valida√ß√£o
        S->>S: Log detalhado do erro
        S->>KP: Publica "tracking.error.detected"
        S->>DB: Marca c√≥digo para revis√£o manual
        Note over DB: status = "needs_review"
    end
```

### **üìä 3. Otimiza√ß√µes de Performance**

#### **Processamento em Lotes**
```typescript
// Pseudo-c√≥digo do processamento otimizado
class BatchTrackingProcessor {
  async processPendingCodes(): Promise<void> {
    const pendingCodes = await this.getPendingCodes(100); // Lote de 100
    
    // Agrupa por transportadora para otimizar rate limits
    const codesByCarrier = this.groupByCarrier(pendingCodes);
    
    for (const [carrier, codes] of codesByCarrier) {
      await this.processCarrierBatch(carrier, codes);
      await this.sleep(1000); // 1s entre transportadoras
    }
  }
  
  async processCarrierBatch(carrier: string, codes: TrackingCode[]): Promise<void> {
    // Processa em paralelo respeitando rate limits
    const concurrency = this.getRateLimitFor(carrier); // Ex: 10 req/min
    
    await Promise.allSettled(
      codes.map(code => 
        this.semaphore.acquire(() => this.processCode(code))
      )
    );
  }
}
```

#### **Cache Inteligente**
```typescript
// Estrat√©gias de cache baseadas no status
class IntelligentCacheStrategy {
  getCacheTTL(trackingStatus: TrackingStatus): number {
    return {
      'delivered': 3600,        // 1h - dados n√£o mudam
      'in_transit': 300,        // 5min - pode mudar
      'out_for_delivery': 60,   // 1min - muda rapidamente
      'exception': 180,         // 3min - situa√ß√£o inst√°vel
      'pending': 900            // 15min - raramente muda
    }[trackingStatus] || 300;
  }
  
  getCacheKey(trackingCode: string, includeEvents: boolean): string {
    return includeEvents 
      ? `tracking:${trackingCode}:full`
      : `tracking:${trackingCode}:summary`;
  }
}
```

---

## üèÜ Crit√©rios de Avalia√ß√£o

### **üéØ Aspectos Avaliados:**
1. **Arquitetura** (25%): Design de microservi√ßos, separa√ß√£o de responsabilidades
2. **C√≥digo** (25%): Qualidade, padr√µes, TypeScript usage
3. **Integra√ß√£o** (20%): Carriers API, Kafka, MongoDB
4. **Testes** (15%): Cobertura, casos edge, mocks
5. **Documenta√ß√£o** (15%): Clareza, completude, exemplos

### **ü•á Bonus Points:**
- **Observabilidade**: M√©tricas customizadas, tracing
- **Security**: Rate limiting, input validation, secrets management
- **Performance**: Otimiza√ß√µes, caching inteligente
- **DevOps**: CI/CD pipeline, health checks avan√ßados

---

